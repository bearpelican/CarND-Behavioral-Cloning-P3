{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'data/models/test3/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, valid_cameras, discard_prob):\n",
    "    df = pd.read_csv(data_dir+'driving_log.csv')\n",
    "    images = []\n",
    "    measurements = []\n",
    "\n",
    "    def fetch_image(data_dir, source_path):\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = data_dir + 'IMG/' + filename\n",
    "        return imageio.imread(current_path)\n",
    "\n",
    "    def append_image(image, measurement):\n",
    "        images.append(image)\n",
    "        measurements.append(measurement)\n",
    "\n",
    "        # flip image\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement_flipped = -measurement\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        measurement = float(row[3])\n",
    "        camera_map = { 1:0.25, 0:0, 2:-0.3 }\n",
    "        if measurement <= 0 and np.random.rand() < discard_prob:\n",
    "            continue\n",
    "        for c in valid_cameras:\n",
    "            image = fetch_image(data_dir, row[c])\n",
    "            append_image(image, measurement + camera_map[c])\n",
    "            \n",
    "    return images, measurements\n",
    "    \n",
    "def load_from_dir(data_dir, discard_prob=0, valid_cameras=[0, 1, 2], load_cached=False):\n",
    "    if load_cached and os.path.exists(data_dir+'X_train.npy'):\n",
    "        X_train = np.load(data_dir+'X_train.npy')\n",
    "        y_train = np.load(data_dir+'y_train.npy')\n",
    "    else:\n",
    "        images, measurements = load_images(data_dir, valid_cameras, discard_prob)\n",
    "        \n",
    "        X_train = np.array(images)\n",
    "        y_train = np.array(measurements)\n",
    "\n",
    "        np.save(data_dir+'X_train.npy', X_train)\n",
    "        np.save(data_dir+'y_train.npy', y_train)\n",
    "    \n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (29898, 160, 320, 3)\n",
      "y_train: (29898,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_from_dir('data/sample_data/', discard_prob=0.5, load_cached=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select images from each bucket for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])\n",
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, BatchNormalization, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA Suggested network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(160,320,3)))\n",
    "# model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(66,200,3))) # Checking with NVidia dimensions\n",
    "model.add(keras.layers.Convolution2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(48, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 78, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 37, 48)        43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 35, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27456)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               2745700   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,882,619\n",
      "Trainable params: 2,882,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23918 samples, validate on 5980 samples\n",
      "Epoch 1/5\n",
      "23918/23918 [==============================] - 28s - loss: 7.4662 - val_loss: 0.0173\n",
      "Epoch 2/5\n",
      "23918/23918 [==============================] - 26s - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 3/5\n",
      "23918/23918 [==============================] - 26s - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 4/5\n",
      "23918/23918 [==============================] - 26s - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 5/5\n",
      "23918/23918 [==============================] - 26s - loss: 0.0107 - val_loss: 0.0131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23918 samples, validate on 5980 samples\n",
      "Epoch 1/4\n",
      "23918/23918 [==============================] - 26s - loss: 0.0103 - val_loss: 0.0140\n",
      "Epoch 2/4\n",
      "23918/23918 [==============================] - 26s - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 3/4\n",
      "23918/23918 [==============================] - 26s - loss: 0.0097 - val_loss: 0.0141\n",
      "Epoch 4/4\n",
      "23918/23918 [==============================] - 26s - loss: 0.0094 - val_loss: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model.h5')\n",
    "model.optimizer.lr.assign(0.005)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=4)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23918 samples, validate on 5980 samples\n",
      "Epoch 1/3\n",
      "23918/23918 [==============================] - 26s - loss: 0.0094 - val_loss: 0.0142\n",
      "Epoch 2/3\n",
      "23918/23918 [==============================] - 26s - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 3/3\n",
      "23918/23918 [==============================] - 26s - loss: 0.0089 - val_loss: 0.0149\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model_2.h5')\n",
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirt roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3468, 160, 320, 3)\n",
      "y_train: (3468,)\n"
     ]
    }
   ],
   "source": [
    "X_train_dirt, y_train_dirt = load_from_dir('data/recorded_data/lap1_dirt_bridge/', discard_prob=0, load_cached=False)\n",
    "# model = keras.models.load_model('data/sample_data/'+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_dirt[2200])\n",
    "print(y_train_dirt[2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3121 samples, validate on 347 samples\n",
      "Epoch 1/7\n",
      "3121/3121 [==============================] - 3s - loss: 0.0056 - val_loss: 0.0117\n",
      "Epoch 2/7\n",
      "3121/3121 [==============================] - 3s - loss: 0.0019 - val_loss: 0.0123\n",
      "Epoch 3/7\n",
      "3121/3121 [==============================] - 3s - loss: 0.0013 - val_loss: 0.0120\n",
      "Epoch 4/7\n",
      "3121/3121 [==============================] - 3s - loss: 0.0011 - val_loss: 0.0117\n",
      "Epoch 5/7\n",
      "3121/3121 [==============================] - 3s - loss: 7.2086e-04 - val_loss: 0.0117\n",
      "Epoch 6/7\n",
      "3121/3121 [==============================] - 3s - loss: 6.2248e-04 - val_loss: 0.0116\n",
      "Epoch 7/7\n",
      "3121/3121 [==============================] - 3s - loss: 5.3836e-04 - val_loss: 0.0117\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train_dirt, y_train_dirt, validation_split=0.1, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23918 samples, validate on 5980 samples\n",
      "Epoch 1/2\n",
      "23918/23918 [==============================] - 26s - loss: 0.0084 - val_loss: 0.0139\n",
      "Epoch 2/2\n",
      "23918/23918 [==============================] - 26s - loss: 0.0078 - val_loss: 0.0137\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1mistakes/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=6)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1mistakes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1reverse/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.optimizer.lr = 0.001\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1reverse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
