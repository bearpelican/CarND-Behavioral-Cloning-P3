{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'data/models/test4/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, valid_cameras, discard_prob):\n",
    "    df = pd.read_csv(data_dir+'driving_log.csv')\n",
    "    images = []\n",
    "    measurements = []\n",
    "\n",
    "    def fetch_image(data_dir, source_path):\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = data_dir + 'IMG/' + filename\n",
    "        return imageio.imread(current_path)\n",
    "\n",
    "    def append_image(image, measurement):\n",
    "        images.append(image)\n",
    "        measurements.append(measurement)\n",
    "\n",
    "        # flip image\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement_flipped = -measurement\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        measurement = float(row[3])\n",
    "        camera_map = { 1:0.22, 0:0, 2:-0.27 }\n",
    "        if measurement <= 0 and np.random.rand() < discard_prob:\n",
    "            continue\n",
    "        for c in valid_cameras:\n",
    "            image = fetch_image(data_dir, row[c])\n",
    "            append_image(image, measurement + camera_map[c])\n",
    "            \n",
    "    return images, measurements\n",
    "    \n",
    "def load_from_dir(data_dir, discard_prob=0, valid_cameras=[0, 1, 2], load_cached=False):\n",
    "    if load_cached and os.path.exists(data_dir+'X_train.npy'):\n",
    "        X_train = np.load(data_dir+'X_train.npy')\n",
    "        y_train = np.load(data_dir+'y_train.npy')\n",
    "    else:\n",
    "        images, measurements = load_images(data_dir, valid_cameras, discard_prob)\n",
    "        \n",
    "        X_train = np.array(images)\n",
    "        y_train = np.array(measurements)\n",
    "\n",
    "        np.save(data_dir+'X_train.npy', X_train)\n",
    "        np.save(data_dir+'y_train.npy', y_train)\n",
    "    \n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/sample_data/', discard_prob=0.5, load_cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine lots of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/sample_data/', discard_prob=0.7, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dirt, y_train_dirt = load_from_dir('data/recorded_data/lap1_dirt_bridge/', discard_prob=0, load_cached=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mis, y_train_mis = load_from_dir('data/recorded_data/lap1mistakes/', discard_prob=0.5, load_cached=False)\n",
    "X_train_lap1, y_train_lap1 = load_from_dir('data/recorded_data/lap1/', discard_prob=0.5, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rev, y_train_rev = load_from_dir('data/recorded_data/lap1reverse/', discard_prob=0.5, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = np.concatenate([X_train, X_train_dirt, X_train_mis, X_train_lap1, X_train_rev])\n",
    "y_train_all = np.concatenate([y_train, y_train_dirt, y_train_mis, y_train_lap1, y_train_rev])\n",
    "np.save('data/all/'+'X_train_all.npy', X_train)\n",
    "np.save('data/all/'+'y_train_all.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = np.load('data/all/'+'X_train_all.npy')\n",
    "y_train_all = np.load('data/all/'+'y_train_all.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select images from each bucket for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])\n",
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, BatchNormalization, Input, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA Suggested network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(160,320,3)))\n",
    "# model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(66,200,3))) # Checking with NVidia dimensions\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(keras.layers.Convolution2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(48, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 160, 320, 3)       640       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 78, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 37, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 17, 37, 48)        43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 17, 37, 48)        68        \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 15, 35, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 27456)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               2745700   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,883,967\n",
      "Trainable params: 2,883,293\n",
      "Non-trainable params: 674\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/7\n",
      "17654/17654 [==============================] - 44s - loss: 0.3055 - val_loss: 0.0539\n",
      "Epoch 2/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0572 - val_loss: 0.0400\n",
      "Epoch 3/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0262 - val_loss: 0.0176\n",
      "Epoch 4/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0212 - val_loss: 0.0159\n",
      "Epoch 5/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0187 - val_loss: 0.0178\n",
      "Epoch 6/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0175 - val_loss: 0.0152\n",
      "Epoch 7/7\n",
      "17654/17654 [==============================] - 39s - loss: 0.0165 - val_loss: 0.0152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_object = model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/3\n",
      "17654/17654 [==============================] - 39s - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 2/3\n",
      "17654/17654 [==============================] - 39s - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 3/3\n",
      "17654/17654 [==============================] - 39s - loss: 0.0152 - val_loss: 0.0155\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model.h5')\n",
    "model.optimizer.lr.assign(0.005)\n",
    "model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/2\n",
      "17654/17654 [==============================] - 40s - loss: 0.0150 - val_loss: 0.0168\n",
      "Epoch 2/2\n",
      "17654/17654 [==============================] - 40s - loss: 0.0146 - val_loss: 0.0149\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model_2.h5')\n",
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirt roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dirt, y_train_dirt = load_from_dir('data/recorded_data/lap1_dirt_bridge/', discard_prob=0, load_cached=False)\n",
    "# model = keras.models.load_model('data/sample_data/'+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_dirt[2200])\n",
    "print(y_train_dirt[2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train_dirt, y_train_dirt, validation_split=0.1, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1mistakes/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=6)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1mistakes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1reverse/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.optimizer.lr = 0.001\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1reverse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
