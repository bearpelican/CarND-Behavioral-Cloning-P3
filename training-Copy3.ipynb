{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'data/models/test5/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(data_dir, valid_cameras, discard_prob):\n",
    "    df = pd.read_csv(data_dir+'driving_log.csv')\n",
    "    images = []\n",
    "    measurements = []\n",
    "\n",
    "    def fetch_image(data_dir, source_path):\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = data_dir + 'IMG/' + filename\n",
    "        return imageio.imread(current_path)\n",
    "\n",
    "    def append_image(image, measurement):\n",
    "        images.append(image)\n",
    "        measurements.append(measurement)\n",
    "\n",
    "        # flip image\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement_flipped = -measurement\n",
    "        images.append(image_flipped)\n",
    "        measurements.append(measurement_flipped)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        measurement = float(row[3])\n",
    "        camera_map = { 1:0.22, 0:0, 2:-0.27 }\n",
    "        if measurement <= 0 and np.random.rand() < discard_prob:\n",
    "            continue\n",
    "        for c in valid_cameras:\n",
    "            image = fetch_image(data_dir, row[c])\n",
    "            append_image(image, measurement + camera_map[c])\n",
    "            \n",
    "    return images, measurements\n",
    "    \n",
    "def load_from_dir(data_dir, discard_prob=0, valid_cameras=[0, 1, 2], load_cached=False):\n",
    "    if load_cached and os.path.exists(data_dir+'X_train.npy'):\n",
    "        X_train = np.load(data_dir+'X_train.npy')\n",
    "        y_train = np.load(data_dir+'y_train.npy')\n",
    "    else:\n",
    "        images, measurements = load_images(data_dir, valid_cameras, discard_prob)\n",
    "        \n",
    "        X_train = np.array(images)\n",
    "        y_train = np.array(measurements)\n",
    "\n",
    "        np.save(data_dir+'X_train.npy', X_train)\n",
    "        np.save(data_dir+'y_train.npy', y_train)\n",
    "    \n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/sample_data/', discard_prob=0.5, load_cached=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine lots of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/sample_data/', discard_prob=0.7, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dirt, y_train_dirt = load_from_dir('data/recorded_data/lap1_dirt_bridge/', discard_prob=0, load_cached=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mis, y_train_mis = load_from_dir('data/recorded_data/lap1mistakes/', discard_prob=0.5, load_cached=False)\n",
    "X_train_lap1, y_train_lap1 = load_from_dir('data/recorded_data/lap1/', discard_prob=0.5, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rev, y_train_rev = load_from_dir('data/recorded_data/lap1reverse/', discard_prob=0.5, load_cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = np.concatenate([X_train, X_train_dirt, X_train_mis, X_train_lap1, X_train_rev])\n",
    "y_train_all = np.concatenate([y_train, y_train_dirt, y_train_mis, y_train_lap1, y_train_rev])\n",
    "np.save('data/all/'+'X_train_all.npy', X_train)\n",
    "np.save('data/all/'+'y_train_all.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = np.load('data/all/'+'X_train_all.npy')\n",
    "y_train_all = np.load('data/all/'+'y_train_all.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select images from each bucket for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[2])\n",
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, BatchNormalization, Input, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA Suggested network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(160,320,3)))\n",
    "# model.add(Lambda(lambda x: x - 255.0 / 255.0, input_shape=(66,200,3))) # Checking with NVidia dimensions\n",
    "model.add(keras.layers.Convolution2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(48, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(keras.layers.Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 78, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 17, 37, 48)        43248     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 35, 64)        27712     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 27456)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               2745700   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,882,619\n",
      "Trainable params: 2,882,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/7\n",
      "17654/17654 [==============================] - 19s - loss: 23.3031 - val_loss: 0.0479\n",
      "Epoch 2/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0293 - val_loss: 0.0357\n",
      "Epoch 3/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0234 - val_loss: 0.0297\n",
      "Epoch 4/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0188 - val_loss: 0.0269\n",
      "Epoch 5/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0156 - val_loss: 0.0268\n",
      "Epoch 6/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0133 - val_loss: 0.0288\n",
      "Epoch 7/7\n",
      "17654/17654 [==============================] - 19s - loss: 0.0120 - val_loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_object = model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJZ7v8DXp7IVsZUUZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f244041a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/3\n",
      "17654/17654 [==============================] - 19s - loss: 0.0114 - val_loss: 0.0245\n",
      "Epoch 2/3\n",
      "17654/17654 [==============================] - 19s - loss: 0.0106 - val_loss: 0.0197\n",
      "Epoch 3/3\n",
      "17654/17654 [==============================] - 19s - loss: 0.0097 - val_loss: 0.0210\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model.h5')\n",
    "model.optimizer.lr.assign(0.005)\n",
    "model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17654 samples, validate on 4414 samples\n",
      "Epoch 1/2\n",
      "17654/17654 [==============================] - 19s - loss: 0.0087 - val_loss: 0.0207\n",
      "Epoch 2/2\n",
      "17654/17654 [==============================] - 19s - loss: 0.0089 - val_loss: 0.0201\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(model_dir+'nvidia_suggested_model_2.h5')\n",
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train_all, y_train_all, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirt roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dirt, y_train_dirt = load_from_dir('data/recorded_data/lap1_dirt_bridge/', discard_prob=0, load_cached=False)\n",
    "# model = keras.models.load_model('data/sample_data/'+'nvidia_suggested_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_dirt[2200])\n",
    "print(y_train_dirt[2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.0001)\n",
    "model.fit(X_train_dirt, y_train_dirt, validation_split=0.1, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr.assign(0.00005)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_dirt2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=7)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1mistakes/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=6)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1mistakes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap1 Reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_dir('data/recorded_data/lap1reverse/', [0, 1, 2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.optimizer.lr = 0.001\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=5)\n",
    "\n",
    "model.save(model_dir+'nvidia_suggested_model_self_lap1reverse.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
